{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc9N8B1hZEfLHpoEqUYMDa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julioquevdo/LorchatbotIA/blob/main/chatbotIA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-Requisitos para começar"
      ],
      "metadata": {
        "id": "IbCPk31J8yDc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enXtSzLBQQZf"
      },
      "outputs": [],
      "source": [
        "pip install -q -U google-generativeai pandas nltk gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "TzWC6h3tXz1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ChatBot Educacional: Lor\n",
        "Apenas substitua o *GOOGLE_API_KEY* para a sua API para começar"
      ],
      "metadata": {
        "id": "-kwkZK_T8tkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import gradio as gr\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "GOOGLE_API_KEY=\"[INSERIR AQUI]\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.5,\n",
        "}\n",
        "\n",
        "safety_settings={\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL' : 'BLOCK_NONE',\n",
        "    'DANGEROUS' : 'BLOCK_NONE'\n",
        "    }\n",
        "\n",
        "# Criar o modelo AQUI, fora da função\n",
        "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings,)\n",
        "\n",
        "# Caminho do arquivo .txt\n",
        "nome_arquivo = \"/content/data/base_de_conhecimento.txt\"\n",
        "\n",
        "# Função para carregar a base de conhecimento\n",
        "def carregar_base_conhecimento(nome_arquivo):\n",
        "    with open(nome_arquivo, \"r\", encoding=\"utf-8\") as f:\n",
        "        texto = f.read()\n",
        "    return texto\n",
        "\n",
        "# Função para buscar conhecimento\n",
        "def buscar_conhecimento(consulta, base_conhecimento):\n",
        "    frases = nltk.sent_tokenize(base_conhecimento)\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vetores = vectorizer.fit_transform(frases)\n",
        "    consulta_vetor = vectorizer.transform([consulta])\n",
        "    similaridades = cosine_similarity(consulta_vetor, vetores).flatten()\n",
        "    indice_mais_semelhante = similaridades.argmax()\n",
        "    return frases[indice_mais_semelhante]\n",
        "\n",
        "# Interface com Gradio\n",
        "def interface_chatbot(entrada_usuario, nivel_complexidade):\n",
        "    resposta = gerenciar_dialogo(entrada_usuario, base_conhecimento, nivel_complexidade)\n",
        "    return resposta\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=interface_chatbot,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Entrada\"),\n",
        "        gr.Radio([\"iniciante\", \"intermediário\", \"avançado\"], label=\"Nível de Complexidade\")\n",
        "    ],\n",
        "    outputs=gr.Markdown(),\n",
        "    title=\"Lor: Chatbot Educacional de IA\"\n",
        ")\n",
        "\n",
        "# Função para gerenciar o diálogo\n",
        "def gerenciar_dialogo(entrada_usuario, base_conhecimento, nivel_complexidade):\n",
        "\n",
        "    # Instruções do sistema\n",
        "    system_instruction = \"\"\"[Gerar a resposta a partir do {estilo} que será fornecido posteriormente] # Configurações \\n\\nnome = \\seu nome \"Lor\\\"\\npersonalidade:\\nAmigável, paciente, informativa e entusiasmada com IA. \\nGosta de ensinar e tornar o conhecimento sobre IA acessível a todos.\\n\\nconhecimento:\\nVocê possui amplo conhecimento em inteligência artificial, machine learning e deep learning, incluindo:\\n* Conceitos fundamentais \\n* Técnicas e algoritmos\\n* Aplicações em diferentes áreas\\n* Tendências atuais e pesquisas recentes\\n\\n# Instruções\\n\\nVocê é a IA Educadora, uma especialista em inteligência artificial, machine learning e deep learning. Sua missão é:\\n\\n* Ensinar as pessoas sobre esses temas de forma clara, concisa e acessível.\\n* Responder a perguntas, mesmo que sejam abertas, desafiadoras ou estranhas. \\n* Explicar conceitos complexos de maneira simples e compreensível.\\n* Fornecer exemplos relevantes e estudos de caso.\\n* Discutir aplicações e implicações éticas da IA.\\n* Aprender novas informações a partir de arquivos de texto e código.\\n* Gerar diferentes respostas criativas de texto, como poemas, código, scripts, peças musicais, e-mail, cartas, etc.\\n* Tentar seguir suas instruções e completar seus pedidos cuidadosamente.\\n\\n# Integração com o banco de dados\\n\\nVocê tem acesso a um banco de dados para auxiliar em suas tarefas. Utilize ele para:\\n\\n* Expandir seu conhecimento e se manter atualizada sobre as últimas pesquisas e desenvolvimentos em IA.\\n* Gerar respostas mais completas e informativas.\\n* Adaptar seu estilo de comunicação ao contexto da conversa.\\n\\n# Exemplo de Interação\\n\\n**Usuário:** O que é inteligência artificial?\\n\\n**IA Educadora:** A inteligência artificial (IA) é um campo amplo da ciência da computação que se concentra na criação de máquinas inteligentes que podem realizar tarefas que normalmente requerem inteligência humana, como aprendizado, resolução de problemas e tomada de decisões. \\n\\n**Usuário:** Você pode me dar alguns exemplos de como a IA está sendo usada hoje?\\n\\n**IA Educadora:** Claro! A IA está sendo usada em uma variedade de indústrias e aplicações, incluindo:\\n\\n* **Assistentes virtuais:** Como Siri e Alexa, que podem entender comandos de voz e realizar tarefas.\\n* **Carros autônomos:** Que usam IA para navegar pelas estradas e evitar obstáculos.\\n* **Diagnóstico médico:** Onde a IA pode ser usada para analisar imagens médicas e identificar doenças.\\n* **Recomendações personalizadas:** Como as que você vê em plataformas de streaming como Netflix e Spotify.\\n\\n**Usuário:** Isso é fascinante! Eu quero aprender mais sobre IA.\\n\\n**IA Educadora:** Ótimo! Eu ficaria feliz em te ensinar mais sobre IA. O que você gostaria de aprender especificamente?\\n\\n# Lembre-se:\\n\\n* Seja sempre respeitosa e evite expressar opiniões pessoais ou crenças.\\n* Mantenha o foco no tema da IA e evite divagações.\\n* Se você não souber a resposta para uma pergunta, admita e ofereça-se para pesquisar mais informações.\"\"\"\n",
        "\n",
        "    # Buscar conhecimento relevante\n",
        "    informacao = buscar_conhecimento(entrada_usuario, base_conhecimento)\n",
        "\n",
        "    # Ajustar o estilo da resposta com base no nível de complexidade\n",
        "    if nivel_complexidade == \"iniciante\":\n",
        "        estilo = \"Explique de forma simples usando analogias e sem muitos conceitos, explique de forma direta e sem muita complexidade. Evite usar muitos tópicos, perceba que deve ser fácil de ser entendido levando em consideração que não existem conhecimento prévio de quem fez a pergunta.\"\"\"\n",
        "    elif nivel_complexidade == \"intermediário\":\n",
        "        estilo = \"Forneça detalhes adicionais e exemplos, levando em consideração que quem fez a pergunta tem um pouco de conhecimento prévio e pode ser que saiba alguns conceitos básicos, caso você use algum conceito mais díficil, adicione um dicionário ao final da resposta.\"\n",
        "    elif nivel_complexidade == \"avançado\":\n",
        "        estilo = \"Use termos técnicos e referências a pesquisas recentes, visto que quem fez essa pergunta é alguem com expertise na área. De respostas mais complexas e elaboradas, puxando conceitos que são vistos dentro da resposta do que foiperguntado\"\n",
        "    else:\n",
        "        estilo = \"\"\"Forneça detalhes adicionais e exemplos, levando em consideração que quem fez a pergunta tem um pouco de conhecimento prévio e pode ser que saiba alguns conceitos básicos, caso você use algum conceito mais díficil, adicione um dicionário ao final da resposta.\"\"\"\n",
        "\n",
        "    # Prompt\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    ## Sua Resposta (como IA Educadora)\n",
        "    {estilo}\n",
        "\n",
        "    {system_instruction}\n",
        "\n",
        "    ## Contexto da Conversa\n",
        "    Aqui está alguma informação relevante:\n",
        "    {informacao}\n",
        "\n",
        "    ## Pergunta do Usuário\n",
        "    {entrada_usuario}\n",
        "    \"\"\"\n",
        "\n",
        "    # Gerar resposta com o Gemini\n",
        "    resposta_gemini = model.generate_content(prompt)\n",
        "    return resposta_gemini.text\n",
        "\n",
        "# Carregar a base de conhecimento\n",
        "base_conhecimento = carregar_base_conhecimento(nome_arquivo)\n",
        "\n",
        "iface.launch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "yMCRV6opi2lB",
        "outputId": "434c44f4-6f68-44e9-f6d0-5060e2264375"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://7e3816b8bdae4e8829.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7e3816b8bdae4e8829.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://7e3816b8bdae4e8829.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Criador de Roteiro de Estudos\n",
        "Apenas substitua o *GOOGLE_API_KEY* para a sua API para começar"
      ],
      "metadata": {
        "id": "o4AJBEXe8RZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import re\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Substitua pela sua API Key\n",
        "GOOGLE_API_KEY = \"[INSERIR AQUI]\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Configurações de geração\n",
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 0.5,\n",
        "}\n",
        "\n",
        "# Configurações de segurança\n",
        "safety_settings = {\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL': 'BLOCK_NONE',\n",
        "    'DANGEROUS': 'BLOCK_NONE'\n",
        "}\n",
        "\n",
        "# Criar o modelo Gemini\n",
        "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "import gradio as gr\n",
        "import re\n",
        "\n",
        "nome_arquivo= \"/content/data/base_roteiro.txt\"\n",
        "\n",
        "# Carrega o arquivo base_roteiro.txt\n",
        "def carregar_base(nome_arquivo):\n",
        "    with open(nome_arquivo, 'r', encoding='utf-8') as f:\n",
        "        conteudo = f.read()\n",
        "    return conteudo\n",
        "\n",
        "def extrair_topicos(conteudo):\n",
        "    topicos = re.findall(r'\\{(.*?)\\}', conteudo, re.DOTALL)\n",
        "    return topicos\n",
        "\n",
        "def extrair_links(conteudo):\n",
        "    links = re.findall(r'(https?://\\S+)', conteudo)\n",
        "    return links\n",
        "\n",
        "# Cria o roteiro de estudos\n",
        "def gerar_roteiro(topico_escolhido, topicos, links):\n",
        "    roteiro = f\"## Roteiro de Estudos: {topico_escolhido}\\n\\n\"\n",
        "    for i, topico in enumerate(topicos):\n",
        "        if topico_escolhido.lower() in topico.lower():\n",
        "            subtopicos = topico.split(\"\\n\")\n",
        "            for subtopico in subtopicos:\n",
        "                if subtopico.strip():\n",
        "                    roteiro += f\"**{subtopico.strip()}**\\n\"\n",
        "            if links:\n",
        "                roteiro += f\"\\n**Links Úteis:**\\n\"\n",
        "                for link in links:\n",
        "                    roteiro += f\"- {link}\\n\"\n",
        "            return roteiro\n",
        "    return f\"Desculpe, não encontrei informações sobre '{topico_escolhido}'.\"\n",
        "\n",
        "# Interface com o Gradio\n",
        "def interface_chatbot(topico):\n",
        "    conteudo = carregar_base()\n",
        "    topicos = extrair_topicos(conteudo)\n",
        "    links = extrair_links(conteudo)\n",
        "    roteiro = gerar_roteiro(topico, topicos, links)\n",
        "    return roteiro\n",
        "\n",
        "\n",
        "# Interface com o Gradio (modificada)\n",
        "def interface_chatbot(topico):\n",
        "  conteudo = carregar_base(nome_arquivo)\n",
        "  topicos = extrair_topicos(conteudo)\n",
        "  links = extrair_links(conteudo)\n",
        "  roteiro = gerar_roteiro(topico, topicos, links)\n",
        "\n",
        "  #Prompr\n",
        "  prompt = f\"\"\"\n",
        "\n",
        "  Crie um roteiro de estudos completo e informativo, em formato markdown, dizendo o porque aquilo deve ser aprendido e quais os pré requisitos para passar para uma nova fase, para o tópico '{topico}' (como o exemplo a seguir),\n",
        "  incluindo os subtópicos e links fornecidos:\n",
        "\n",
        "  {roteiro}\n",
        "\n",
        "  ##exemplo de roteiro de estudos\n",
        "\n",
        "  #substitua o campo (link) pelo link apropriado para o tópico desejado\n",
        "\n",
        "  ## Exemplo de Roteiro de Estudos\n",
        "\n",
        "**Fase 1: Fundamentos\n",
        "*Fundamento 1\n",
        "  *conceito do fundamento 1 (link)\n",
        "  *conceitos do fundamento 1\n",
        "  *conceitos do fundamento 1\n",
        "  *conceitos do fundamento 1(link)\n",
        "\n",
        "**Pré-requisitos para Fase 2:\n",
        "\n",
        "**Fase 2: Análise de Dados e Web Scraping**\n",
        "\n",
        "*Fundamento 1\n",
        "  *conceito do fundamento 1(link)\n",
        "  *conceitos do fundamento 1(link)\n",
        "  *conceitos do fundamento 1(link)\n",
        "  *conceitos do fundamento 1\n",
        "*Fundamento 2\n",
        "  *conceito do fundamento 2\n",
        "  *conceitos do fundamento 2(link)\n",
        "  *conceitos do fundamento 2(link)\n",
        "  *conceitos do fundamento 2\n",
        "\n",
        "\n",
        "**Dicas para se manter informado e continuar aprendendo:**\n",
        "\n",
        "* **Siga especialistas e comunidades no Twitter:**\n",
        "    *exemplo de twitter\n",
        "* **Assine newsletters relevantes:**\n",
        "  *exemplo de newsletters (link)\n",
        "  *exemplo de newsletters\n",
        "* **Leia artigos científicos e blogs:**\n",
        "  *exemplo de artigos\n",
        "  *exemplo de blogs\n",
        "* **Participe de eventos e workshops:**\n",
        "* **Contribua para projetos open-source:**\n",
        "\n",
        "##Observações\n",
        "Caso você não ter um link que seja pertinente, não precisa adicionar.\n",
        "Siga essa estrutura, fases, pré-requisitos e dicas para se manter informado e continuar aprendendo. Diga também o porque aquilo deve ser aprendido.\n",
        "Se o tópico que for requisitado não for relacionado a Inteligência Artificial, diga \"Desculpe, não encontrei informações sobre '{topico}'.\"\n",
        "  \"\"\"\n",
        "\n",
        "  resposta_gemini = model.generate_content(prompt)\n",
        "  return resposta_gemini.text\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=interface_chatbot,\n",
        "    inputs=gr.Textbox(label=\"Digite o tópico desejado:\"),\n",
        "    outputs=gr.Markdown(),\n",
        "    title=\"Chatbot de Roteiros de Estudos\"\n",
        ")\n",
        "\n",
        "iface.launch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "ceLWr9L_0leY",
        "outputId": "b6d3480e-b334-4e0f-a24b-4db0a3b55e7c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://e2b04a367164fa32ec.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e2b04a367164fa32ec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://e2b04a367164fa32ec.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}